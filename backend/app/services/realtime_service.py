"""
Servi√ßo de Monitoramento em Tempo Real
Captura eventos do leitor iDFace continuamente
backend/app/services/realtime_service.py
"""
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from app.utils.idface_client import idface_client
import logging

logger = logging.getLogger(__name__)


class RealtimeMonitorService:
    """Servi√ßo para monitorar eventos em tempo real do iDFace"""
    
    def __init__(self, db):
        self.db = db
        self.last_alarm_check = None
        self.last_log_id = None
    
    async def check_alarm_status(self) -> Dict[str, Any]:
        """
        Verifica status de alarme do dispositivo
        Equivalente a: POST alarm_status.fcgi
        
        Returns:
            {"active": bool, "cause": int}
        """
        try:
            async with idface_client:
                result = await idface_client.request(
                    "POST",
                    "alarm_status.fcgi"
                )
                
                self.last_alarm_check = datetime.now()
                
                return {
                    "success": True,
                    "active": result.get("active", False),
                    "cause": result.get("cause", 0),
                    "timestamp": self.last_alarm_check.isoformat()
                }
                
        except Exception as e:
            logger.error(f"Erro ao verificar alarme: {e}")
            return {
                "success": False,
                "error": str(e),
                "active": False,
                "cause": 0
            }
    
    async def get_new_access_logs(self, since_id: Optional[int] = None) -> Dict[str, Any]:
        """
        Busca novos logs de acesso desde o √∫ltimo ID conhecido.
        Segue o padr√£o EXATO da API iDFace conforme capturas de rede real.
        
        Args:
            since_id: ID do √∫ltimo log processado no nosso banco
        
        Returns:
            Dict com novos logs, contagem e √∫ltimo ID processado
        """
        try:
            # 1. Determinar timestamp de corte
            since_timestamp = 0
            if since_id:
                last_log = await self.db.accesslog.find_unique(
                    where={"id": since_id}
                )
                if last_log:
                    # ‚ö†Ô∏è IMPORTANTE: Subtrair 1 segundo porque a API iDFace retorna
                    # logs com timestamp > since_timestamp (n√£o >=)
                    # Se n√£o subtrairmos, n√£o retorna novos logs com timestamp igual
                    since_timestamp = int(last_log.timestamp.timestamp()) - 1
                    logger.info(f"üîç Buscando logs desde ID {since_id} (timestamp: {since_timestamp})")
            else:
                logger.info(f"üîç Primeira busca: buscando TODOS os logs (since_timestamp=0)")
            
            # 2. Buscar logs filtrados do dispositivo
            logger.info(f"üì° Chamando load_access_logs_filtered(since_timestamp={since_timestamp})")
            async with idface_client:
                result = await idface_client.load_access_logs_filtered(
                    since_timestamp=since_timestamp,
                    limit=7  # ‚úÖ Conforme frontend real
                )
                
                device_logs = result.get("access_logs", [])
            
            logger.info(f"üìä Device retornou {len(device_logs)} logs")
            if device_logs:
                logger.info(f"   Primeiros logs: {[l.get('id') for l in device_logs[:3]]}")
            
            # 3. Enriquecer cada log com dados do usu√°rio e √°rea
            enriched_logs = []
            for log_data in device_logs:
                log_id_device = log_data.get("id")
                if not log_id_device:
                    continue
                
                # Verificar duplicata
                existing = await self.db.accesslog.find_unique(
                    where={"idFaceLogId": log_id_device}
                )
                if existing:
                    continue
                
                # ‚úÖ Buscar dados do usu√°rio
                if log_data.get("user_id"):
                    try:
                        async with idface_client:
                            user_result = await idface_client.load_users_by_id(log_data["user_id"])
                            user_data = user_result.get("users", [{}])[0]
                            log_data["user_name"] = user_data.get("name", "Desconhecido")
                            log_data["registration"] = user_data.get("registration", "")
                    except Exception as e:
                        logger.warning(f"Erro ao buscar usu√°rio {log_data.get('user_id')}: {e}")
                        log_data["user_name"] = "Desconhecido"
                        log_data["registration"] = ""
                
                # ‚úÖ Buscar dados da √°rea/portal
                if log_data.get("portal_id"):
                    try:
                        async with idface_client:
                            area_result = await idface_client.load_areas(
                                where_field="id",
                                where_value=log_data["portal_id"]  # ID do portal/√°rea
                            )
                            area_data = area_result.get("areas", [{}])[0]
                            log_data["area_name"] = area_data.get("name", "Entrada")
                    except Exception as e:
                        logger.warning(f"Erro ao buscar √°rea: {e}")
                        log_data["area_name"] = "Entrada"
                
                enriched_logs.append(log_data)
            
            # 4. Processar e salvar logs novos
            saved_logs = []
            for log_data in enriched_logs:
                saved_log = await self._process_and_save_log(log_data)
                if saved_log:
                    saved_logs.append(saved_log)
            
            # 5. Retornar √∫ltimo ID
            last_id = None
            if saved_logs:
                latest = await self.db.accesslog.find_first(
                    order={"id": "desc"}
                )
                if latest:
                    last_id = latest.id
            elif since_id:
                last_id = since_id
            
            return {
                "success": True,
                "newLogs": saved_logs,
                "count": len(saved_logs),
                "lastId": last_id,
                "timestamp": datetime.now().isoformat()
            }
                
        except Exception as e:
            logger.error(f"Erro ao buscar novos logs: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "newLogs": [],
                "count": 0,
                "lastId": since_id
            }
    
    async def _process_and_save_log(self, log_data: Dict) -> Optional[Dict]:
        """
        Processa e salva log no banco local
        Evita duplicatas usando idFaceLogId
        ‚úÖ Corrigido para validar foreign keys antes de criar
        """
        try:
            log_id_device = log_data.get("id")
            if not log_id_device:
                logger.warning("Log sem ID recebido")
                return None
            
            logger.info(f"üìù Processando log #{log_id_device} do device")
            
            # Verificar se j√° existe
            existing = await self.db.accesslog.find_unique(
                where={"idFaceLogId": log_id_device}
            )
            if existing:
                logger.debug(f"   ‚è≠Ô∏è  Log #{log_id_device} j√° existe no banco")
                return None
            
            # Mapear evento
            event = self._map_event_type(log_data)
            logger.info(f"   üìä Evento: {event}")
            
            # ‚úÖ Converter timestamp Unix para datetime
            unix_timestamp = log_data.get("time", 0)
            if unix_timestamp:
                timestamp = datetime.fromtimestamp(unix_timestamp)
            else:
                timestamp = datetime.now()
            logger.info(f"   üïê Timestamp: {timestamp.isoformat()}")
            
            # ‚úÖ VALIDAR FOREIGN KEYS: Verificar se usu√°rio existe
            user_id_device = log_data.get("user_id")
            user_id_db = None
            user = None
            
            if user_id_device:
                # Procurar usu√°rio pelo idFaceId
                user = await self.db.user.find_unique(
                    where={"idFaceId": user_id_device}
                )
                if user:
                    user_id_db = user.id
                    logger.info(f"   üë§ Usu√°rio encontrado: {user.name} (iDFace #{user_id_device} ‚Üí DB #{user_id_db})")
                else:
                    # Usu√°rio n√£o existe no banco - deixar como null
                    logger.warning(f"   ‚ö†Ô∏è  Usu√°rio iDFace #{user_id_device} n√£o cadastrado no banco")
                    user_id_db = None
            
            # ‚úÖ VALIDAR FOREIGN KEYS: Verificar se portal existe
            portal_id_device = log_data.get("portal_id")
            portal_id_db = None
            portal = None
            
            if portal_id_device:
                # Procurar portal pelo idFaceId
                portal = await self.db.portal.find_unique(
                    where={"idFaceId": portal_id_device}
                )
                if portal:
                    portal_id_db = portal.id
                    logger.info(f"   üö™ Portal encontrado: {portal.name} (iDFace #{portal_id_device} ‚Üí DB #{portal_id_db})")
                else:
                    # Portal n√£o existe no banco - deixar como null
                    logger.warning(f"   ‚ö†Ô∏è  Portal iDFace #{portal_id_device} n√£o cadastrado no banco")
                    portal_id_db = None
            
            # Criar log no banco (userId e portalId podem ser null)
            new_log = await self.db.accesslog.create(
                data={
                    "idFaceLogId": log_id_device,
                    "userId": user_id_db,  # ‚úÖ Pode ser null
                    "portalId": portal_id_db,  # ‚úÖ Pode ser null
                    "event": event,
                    "reason": None,
                    "cardValue": None,
                    "timestamp": timestamp
                }
            )
            
            logger.info(f"   ‚úÖ Log salvo com sucesso! ID no banco: {new_log.id}")
            
            # Retornar formatado
            return {
                "id": new_log.id,
                "idFaceLogId": new_log.idFaceLogId,
                "userId": new_log.userId,
                "userName": user.name if user else log_data.get("user_name", "Desconhecido"),
                "portalId": new_log.portalId,
                "portalName": portal.name if portal else log_data.get("area_name", "Entrada"),
                "event": new_log.event,
                "timestamp": new_log.timestamp.isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erro ao processar log: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _map_event_type(self, log_data: Dict) -> str:
        """
        Mapeia tipo de evento do iDFace para nosso sistema
        ‚úÖ Baseado em dados REAIS do frontend:
        - event = 7: Acesso normal/autorizado
        - event = 0: Acesso negado
        - log_type_id = -1: Tipo gen√©rico
        """
        event_code = log_data.get("event", 0)
        
        # ‚úÖ Mapear baseado em dados reais
        if event_code == 7:
            return "access_granted"
        elif event_code == 0:
            return "access_denied"
        elif event_code == 1:
            return "access_denied"
        else:
            return "unknown"
    
    async def get_access_log_count(self) -> Dict[str, Any]:
        """
        Conta total de logs de acesso no dispositivo
        Equivalente ao COUNT(*) que o frontend faz
        """
        try:
            async with idface_client:
                result = await idface_client.request(
                    "POST",
                    "load_objects.fcgi",
                    json={
                        "join": "LEFT",
                        "object": "access_logs",
                        "fields": ["COUNT(*)"],
                        "where": [],
                        "order": ["id"],
                        "offset": 0
                    }
                )
                
                count = result.get("count", 0)
                
                return {
                    "success": True,
                    "count": count,
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Erro ao contar logs: {e}")
            return {
                "success": False,
                "error": str(e),
                "count": 0
            }
    
    async def get_recent_activity(self, minutes: int = 5) -> Dict[str, Any]:
        """
        Retorna atividade recente (√∫ltimos X minutos)
        Combina dados do banco local
        """
        since = datetime.now() - timedelta(minutes=minutes)
        
        try:
            logs = await self.db.accesslog.find_many(
                where={
                    "timestamp": {"gte": since}
                },
                include={
                    "user": True,
                    "portal": True
                },
                order={"timestamp": "desc"}
            )
            
            formatted_logs = [
                {
                    "id": log.id,
                    "event": log.event,
                    "userName": log.user.name if log.user else "Desconhecido",
                    "portalName": log.portal.name if log.portal else "N/A",
                    "timestamp": log.timestamp.isoformat(),
                    "reason": log.reason
                }
                for log in logs
            ]
            
            return {
                "success": True,
                "logs": formatted_logs,
                "count": len(formatted_logs),
                "period": f"√öltimos {minutes} minutos"
            }
            
        except Exception as e:
            logger.error(f"Erro ao buscar atividade recente: {e}")
            return {
                "success": False,
                "error": str(e),
                "logs": [],
                "count": 0
            }
    
    async def monitor_full_status(self, since_id: Optional[int] = None) -> Dict[str, Any]:
        """
        Retorna status completo do sistema em tempo real
        Combina alarme + logs recentes + estat√≠sticas
        """
        # Buscar dados em paralelo
        alarm_status = await self.check_alarm_status()
        new_logs = await self.get_new_access_logs(since_id)
        log_count = await self.get_access_log_count()
        
        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "alarm": {
                "active": alarm_status.get("active", False),
                "cause": alarm_status.get("cause", 0)
            },
            "logs": {
                "newCount": new_logs.get("count", 0),
                "totalCount": log_count.get("count", 0),
                "lastId": new_logs.get("lastId"),
                "newlyFound": new_logs.get("newLogs", [])
            },
            "deviceStatus": "online" if alarm_status.get("success") else "offline"
        }